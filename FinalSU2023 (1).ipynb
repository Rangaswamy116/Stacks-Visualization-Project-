{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71949e5",
   "metadata": {},
   "source": [
    "# Part 1 PCA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d37cbf",
   "metadata": {},
   "source": [
    "For this part of the project, you will be using the MNIST fashion data which can be reached as(there are many ways to reach out the data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc97c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd22b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistX = mnist['data']\n",
    "mnistX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22aba20",
   "metadata": {},
   "source": [
    "First apply PCA to the training data to find the transformation into a lower dimensional space.\n",
    "How many dimensions do we need to explain 90% of the total variation in the data?\n",
    "Apply the SAME centering and projection to the test data,What dimension did we embed into?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36823eae",
   "metadata": {},
   "source": [
    "A natural question to ask is what did we gain from this projection? Well, our algorithms will run MUCH\n",
    "faster on the reduced dimension data. Will we sacrifice accuracy for this speed boost? For this section,\n",
    "I would like you to run K-NN on the original data and on the reduced dimension\n",
    "data from PCA (NOTE: IN YOUR WRITE-UP, PLEASE GIVE A SHORT TEXT DESCRIPTION OF\n",
    "EACH CLASSIFIER BEFORE YOU USE IT).\n",
    "Use 10-fold Cross validation repeated 10 times to tune K\n",
    "• Consider K = 1, 2, 3, 4, 5, 6 in the repeated CV\n",
    "• Include a running time evaluation\n",
    "• Here I would like you to compare performance across data sets both based on accuracy (on the test\n",
    "data) AND on running time\n",
    "• How do the estimated test accuracies obtained from Cross Validation compare with the accuracies on\n",
    "the actual test data? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13340836",
   "metadata": {},
   "source": [
    "# Part 2 Comparing across classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247af4c7",
   "metadata": {},
   "source": [
    "For the next section, you will compare the performance of multiple classifiers (tuned via CV) on the test\n",
    "data. You will run these classifiers on the dimension reduced PCA data (NOTE: IN YOUR WRITE-UP,\n",
    "PLEASE GIVE A SHORT TEXT DESCRIPTION OF EACH CLASSIFIER BEFORE YOU USE IT).\n",
    "• REMEMBER TO TRAIN THE FINAL MODEL ON THE FULL TRAINING SET AFTER TUNING\n",
    "THE PARAMETERS\n",
    "• I would like you to run the following classifiers using 10-fold CV repeated 5 times to tune the parameters\n",
    "– Linear SVM\n",
    "– Radial Basis SVM \n",
    "• I would also like you to train a Random Forest \n",
    "• I would also like you to train an LDA model \n",
    "• I would also like you to train a QDA model \n",
    "For each model, I would like you to compare across both test accuracy and running time. In particular, I\n",
    "would like you to address\n",
    "• (*)Which model would you choose out of the above (including K-NN)? Why would you make this choice?\n",
    "• For the models that provide a test error estimate (Random Forest via the error and the CV-tuned\n",
    "models via cross validation), which would you have chosen based on the estimated test error? Explain\n",
    "how this relates to your answer to question (*)?\n",
    "• For the models that do not immediately provide a test error estimate (LDA and QDA), how could you\n",
    "estimate test error (Hint: CV)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09cd24",
   "metadata": {},
   "source": [
    "# Part 3 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128c1c9",
   "metadata": {},
   "source": [
    "Download the Mall Customer Segmentation Data from our github repo and determine the optimum \"k\" value using the elbow method and visualize the determined categories with 3D plot (Age vs. Incompe vs. Spending Score). Play with view angles to see the two groups of the high income people (making more than $80k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fd1982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income (k$)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Gender  Age  Annual Income (k$)  Spending Score (1-100)\n",
       "0           1    Male   19                  15                      39\n",
       "1           2    Male   21                  15                      81\n",
       "2           3  Female   20                  16                       6\n",
       "3           4  Female   23                  16                      77\n",
       "4           5  Female   31                  17                      40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ekacar1/Data_for_Lectures/main/Mall_Customers.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd65007",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b3fb5",
   "metadata": {},
   "source": [
    "Create a new set of toy datasets for regression problems. Come up with your own ideas on different datasets of varying difficulty, that would help you compare the pros & cons of different algorithms. Use these datasets to visualize LinearRegression, Support Vector Regression, Nearest Neighbor Regression, and Decision Trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
